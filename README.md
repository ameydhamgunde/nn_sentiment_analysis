# Comparing CNN’s, RNN’s, and Transformers on Sentiment Analysis of Movie Reviews

## Abstract
The transformer architecture is a relatively new and powerful ML tool that uses attention mechanisms to process and 'learn from' extremely large sequences of data, which has made it increasingly popular for NLP tasks such as sentiment analysis, language translation, and text classification. Transformers are replacing the previously dominant CNN/RNN architectures which excelled at images or NLP classification style tasks. This paper explores and compares the performance of these architectures by training 4 models: CNN, RNN, CNN+RNN, and transformer in a closed environment to evaluate their differences, and whether CNN/RNN models are still viable. It is found that CNN and RNN based models achieve testing accuracies of ~89\%, 3\% higher than the transformer at 86\%, with less than half the parameters and a fraction of the training time.

https://github.com/ameydhamgunde/nn_sentiment_analysis/blob/main/413_Project_Proposal.pdf
